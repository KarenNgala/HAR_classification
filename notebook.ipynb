{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human Activity Recognition Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset consists of sensor data from smartphones that can be used to predict the activity a person is engaged in, such as walking, sitting, or standing. Our main objective is to build and evaluate machine learning models to predict human activities accurately based on smartphone sensor data.\n",
    "\n",
    "The dataset is divided into two main files: `train.csv` and `test.csv`, with a 7:3 ratio for training and testing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.expand_frame_repr', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"datasets/train.csv\")\n",
    "test_data = pd.read_csv(\"datasets/test.csv\")\n",
    "\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape\n",
    "\n",
    "print(f'Shape of Train data: {train_data.shape}')\n",
    "print(f'Shape of Test data: {test_data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values\n",
    "\n",
    "print(f'Missing values in Train data: {train_data.isnull().values.sum()}')\n",
    "print(f'Missing values in Test data: {test_data.isnull().values.sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target\n",
    "pd.crosstab(index=train_data[\"Activity\"],  # Make a crosstab\n",
    "                  columns=\"count\")         # Name the count column\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X_train = pd.DataFrame(train_data.drop(['Activity','subject'],axis=1))\n",
    "y_train = train_data.Activity.values.astype(object)\n",
    "\n",
    "X_test = pd.DataFrame(test_data.drop(['Activity','subject'],axis=1))\n",
    "y_test= test_data.Activity.values.astype(object)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection & evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate classifier models performance on the dataset:\n",
    "\n",
    "- Decision Tree\n",
    "- Random Forest\n",
    "- Support Vector Machine (SVM)\n",
    "- k-Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_model = DecisionTreeClassifier()\n",
    "dtc_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = SVC()\n",
    "svm_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = KNeighborsClassifier()\n",
    "knn_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, y):\n",
    "    y_pred = model.predict(X)\n",
    "    \n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    precision = precision_score(y, y_pred, average='weighted')\n",
    "    recall = recall_score(y, y_pred, average='weighted')\n",
    "    f1 = f1_score(y, y_pred, average='weighted')\n",
    "    \n",
    "    cm = confusion_matrix(y, y_pred)\n",
    "\n",
    "    return accuracy, precision, recall, f1, cm\n",
    "\n",
    "dt_accuracy, dt_precision, dt_recall, dt_f1, dt_cm = evaluate_model(dtc_model, X_test, y_test)\n",
    "rf_accuracy, rf_precision, rf_recall, rf_f1, rf_cm = evaluate_model(rf_model, X_test, y_test)\n",
    "svm_accuracy, svm_precision, svm_recall, svm_f1, svm_cm = evaluate_model(svm_model, X_test, y_test)\n",
    "knn_accuracy, knn_precision, knn_recall, knn_f1, knn_cm = evaluate_model(knn_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Model Performance\n",
    "model_performances = {\n",
    "    \"Decision Tree\": (dt_accuracy, dt_precision, dt_recall, dt_f1, dt_cm),\n",
    "    \"Random Forest\": (rf_accuracy, rf_precision, rf_recall, rf_f1, rf_cm),\n",
    "    \"Support Vector Machine\": (svm_accuracy, svm_precision, svm_recall, svm_f1, svm_cm),\n",
    "    \"K-Nearest Neighbors\": (knn_accuracy, knn_precision, knn_recall, knn_f1, knn_cm)\n",
    "}\n",
    "\n",
    "print(f\"Model Comparison:\")\n",
    "for model_name, (accuracy, precision, recall, f1, _) in model_performances.items():\n",
    "    print(f\"{model_name}:\")\n",
    "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"  Precision: {precision:.4f}\")\n",
    "    print(f\"  Recall: {recall:.4f}\")\n",
    "    print(f\"  F1-score: {f1:.4f}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model that best suits the main objective of this analysis is the Support Vector Machine(SVM) with an accuracy of 95% on the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flaws and Plan of Action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Potential flaws in the model may include overfitting or underfitting. To address this, we can revisit the analysis with additional data if available or experiment with different predictive modeling techniques.\n",
    "- Further fine-tuning and hyperparameter optimization could be considered to improve model performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtual",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
